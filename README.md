# Continuous-Time-Transformer-For-Channel-Prediction
The pytorch implementation of our paper “Continuous-Time Transformer Based Channel Prediction with Non-Uniform Pilot Pattern”.

## Checkpoint and test data set download
Please download checkpoint (.pth format) and test data set (.mat format) from Tsinghua Cloud: https://cloud.tsinghua.edu.cn/d/b369c2aab6b445e7a067/. Then, extract them in the corresponding `./checkpoint`, `./3GPP_dataset`, and `deepmimo_dataset` folders.  

## File Description
 - `./3GPP_dataset` containing test dataset for 3GPP TR 38.901 channels.
 - `./DeepMIMO_O1_28B_matlab` containing matlab code for generating Outdoor 1 Blockage dataset.
 - `./eval_dataset` test data set folder.
 - `./trained_model` trained model folder.
 - `./our_results` This folder contains the results generated by our previously executed programs.
 - `dataloader_MTL.py` code for data loading.
 - `model_MTL.py` code containing all function templates for models. Specifically, `Bs`, `bt`, and `Up` represent the single-task learning models for BS prediction, beam tracking, and UE positioning, respectively. `Vanilla` denotes the vanilla multi-task learning model. `Bs2bt2Up` is the single-cascaded multi-task learning model. `Up2bt2Bs` is the inversed single-cascaded multi-task learning model. `Dual_Cascaded` is the proposed dual-cascaded multi-task learning model.
 - `eval_MTL.py` eval different models.
 - `cosine_similarity.py` calculate cosine similarity between multi-task gradients to clarify theoretical justification for the proposed loss descending rate-based weighting.

## Keyword arguments
In our code, we have provided detailed comments. Below are the specific meanings of some keywords:
 - `b` batch size.
 - `his_len` historical sequence length.
 - `BS_num` BS number.
 - `beam_num` beam number.


## Keyword arguments within runnable code files
...

## Reproduce the experimental result
...
